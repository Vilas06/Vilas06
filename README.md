### Hi there ðŸ‘‹

<!--
**Vilas06/Vilas06** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Bellabeat Capstone Project

Scenario
	I am a junior data analyst working at Bellabeat a high-tech manufacturer of health-focused products for women. It is a successful small company, but they have the potential to become a larger player in the global smart device market. 

1.	Ask
ïƒ˜	Problem Statement: To focus on one of Bellabeatâ€™s products and analyse the smart device data to gain insight into how consumers are using their smart devices which will help in guiding marketing strategy for the company.
ïƒ˜	Business Task: Analyse the smart device usage by the customers who use the non-Bellabeat smart devices and identify the trend in that. Then, using this information identify how these trends can be implemented on the Bellabeat customers to increase the profit, growth of the company and make the company influence more users to buy subscription for Bellabeat.
ïƒ˜	Stakeholders:
â€¢	UrÅ¡ka SrÅ¡en (Bellabeatâ€™s cofounder and Chief Creative Officer)
â€¢	Sando Mur (Mathematician and Bellabeatâ€™s cofounder; key member of the Bellabeat executive team) 
â€¢	Bellabeat marketing analytics team (team of data analysts)

2.	Prepare
About the data: The data is taken from Kaggle data set which contains personal fitness tracker from thirty fitbit users. This dataset was generated by Thirty eligible Fitbit users consented to the submission to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016. The eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.
	There is a total of 18 .csv files in the downloaded dataset out of which dailyactivity, hourlysteps and sleepday  will be considered for analysis as it would provide useful insights in completing the business task. 

Applying ROCCC approach to identify the credibility of the data:
ïƒ˜	Reliable â€“ The data is taken from only 30 individuals for a period of  2 days which would induce the sample bias issue and hence not reliable. to obtain meaningful trends and insights the data had to be taken from more than 10k users for a period of 6 months.
ïƒ˜	Original â€“ The data is collected by Amazon mechanical Turk which would mean that this is a second party data. It would be original if the Bellabeat company itself had collected the data directly from its customers.
ïƒ˜	Comprehensive â€“ The data is not comprehensive as it is missing many of the information of the customers who completed the survey such as age, sex etc.
ïƒ˜	Current â€“ It is an outdated data since the data is almost 11 years old.
ïƒ˜	Cited â€“ The data is from a cited and vetted company which is Amazon and hence the data is cited.

3.	Process
     This step involves cleaning, verifying, and processing the data for analysis. I would go ahead with R language due to the ease of analysis and variety of packages it offers. Now I will be using the prepared data to verify, clean and transform the data for analysis.
# load the packages
install.packages("tidyverse")
install.packages("skimr")
install.packages("janitor")
install.packages("ggplot2")
install.packages("lubridate")
install.packages("readr")
install.packages("tidyr")
install.packages("dplyr")
install.packages("lubridate")
library(lubridate)
library(ggplot2)
library(readr)
library(tidyr)
library(dplyr)
library(tidyverse)
library(skimr)
library(janitor)
library(lubridate)

# Set working directory
setwd("D:/DA Learning/Capstone")

# Read the csv files
activity_daily <- read.csv("dailyActivity_merged.csv")
steps <- read.csv("hourlySteps_merged.csv")
sleep_daily <- read.csv("sleepDay_merged.csv")

# check the data
head(activity_daily)
head(steps)
head(sleep_daily)
colnames(activity_daily)
colnames(steps)
colnames(sleep_daily)
View(activity_daily)
View(steps)
View(sleep_daily)

#identify number of unique data
n_unique(activity_daily$Id)
n_unique(steps$Id)
n_unique(sleep_daily$Id)

#identify the number of duplicate data
sum(duplicated(activity_daily))
sum(duplicated(steps))
sum(duplicated(sleep_daily))

#remove duplicates
activity_daily_wodup <- activity_daily %>%
  distinct() %>%
  drop_na()

steps_wodup <- steps %>%
  distinct() %>%
  drop_na()

sleep_daily_wodup <- sleep_daily %>%
  distinct() %>%
  drop_na()

sum(duplicated(activity_daily_wodup))
sum(duplicated(steps_wodup))
sum(duplicated(sleep_daily_wodup))

#convert the date to specific format

activity_daily_wodup <- activity_daily_wodup %>%
  mutate(ActivityDate = as.Date(ActivityDate, format = "%m/%d/%Y"))
str(activity_daily_wodup)


str(sleep_daily_wodup)
sleep_daily_wodup <- sleep_daily_wodup %>%
  mutate(SleepDay = as_date(SleepDay,format ="%m/%d/%Y %I:%M:%S %p" , tz=Sys.timezone()))

str(steps_wodup)
str(steps_wodup_t)
View(steps_wodup_t)
steps_wodup_t <- steps_wodup %>%
  mutate(ActivityHour = as.Date(ActivityHour,format ="%m/%d/%Y %I:%M:%S %p" , tz=Sys.timezone()))

#activity analysis
View(activity_daily_wodup)
activity_average <- activity_daily_wodup %>%
  group_by(Id) %>%
  summarise (mean_daily_steps = mean(TotalSteps),mean_daily_calories = mean(Calories))

head(activity_average)


4.	Analyse
In this step I will be finding insights that will answer the business questions and identifies the trends using the processed data. 

#sleep analysis
View(sleep_daily_wodup)
sleep_average <- sleep_daily_wodup%>%
  group_by(Id) %>% 
  summarise(mean_time_sleep = mean(TotalMinutesAsleep),mean_time_inbed = mean(TotalTimeInBed))
head(sleep_average)

#steps analysis
View(steps_wodup)
steps_per_hour <- steps_wodup %>% 
  group_by(Id) %>% 
  separate (ActivityHour, into = c("date", "time"), sep= " ") %>%
  mutate(date = ymd(date)) 

View(steps_per_hour)

#analyse
#steps analysis
steps_per_hour %>%
  group_by(time) %>%
  summarize(average_steps = mean(StepTotal)) %>%
  ggplot() +
  geom_col(mapping = aes(x=time, y = average_steps, fill = average_steps)) + 
  labs(title = "Steps per hour in a day", x="Hour", y="Steps") + 
  scale_fill_gradient(low = "blue", high = "green")+
  theme(axis.text.x = element_text(angle = 45)) 

#calory analysis
ggplot(activity_daily_wodup, aes(x=TotalSteps, y=Calories))+
  geom_line()+
  geom_smooth(color = "red") + 
  labs(title = "Daily steps vs Calories", x = "Daily steps", y= "Calories") +
  theme(panel.background = element_blank(),
        plot.title = element_text( size=16))

#activity analysis
VeryActiveMin <- sum(activity_daily_wodup$VeryActiveMinutes)
FairlyActiveMin <- sum(activity_daily_wodup$FairlyActiveMinutes)
LightlyActiveMin <- sum(activity_daily_wodup$LightlyActiveMinutes)
SedentaryMin <- sum(activity_daily_wodup$SedentaryMinutes)
TotalMin <- VeryActiveMin + FairlyActiveMin + LightlyActiveMin + SedentaryMin

slices <- c(VeryActiveMin,FairlyActiveMin,LightlyActiveMin,SedentaryMin)
lbls <- c("VeryActive","FairlyActive","LightlyActive","Sedentary")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct)
lbls <- paste(lbls, "%", sep="")
paint <- c("green", "blue", "yellow", "red2")
pie(slices, col = paint, main = "Percentage of Activity in Minutes")
legend("bottomright",lbls,fill=paint)

#sleep analysis
ggplot(data=sleep_daily_wodup, aes(x=TotalMinutesAsleep, y = TotalTimeInBed, color=TotalMinutesAsleep))+ 
  geom_point()+ 
  labs(title="Total Minutes Asleep vs TotalTimeInBed")+
  xlab("Total Minutes Alseep")+
  stat_smooth(method=lm)+
  scale_color_gradient(low="red4", high="palegoldenrod")
 
5.	Share
Using graphical representation from the analyse phase, I will be presenting my finding. The identified trends are as mentioned below â€“ 
ïƒ˜	There are very fewer active members i.e., whose step count are more than 10k per day.
ïƒ˜	The suggested minimum of 7 hours of sleep was mostly not achieved on average by the participating individuals.
ïƒ˜	The data logging/tracking was very irregular on most of the days over the course of the month by the participating individuals, and the sleep or weight was not even logged/tracked by few of them.
ïƒ˜	The participants prefer to walk more during the late evening time since the highest number of average steps was logged during that time and there is a positive correlation between steps and calories.
ïƒ˜	The sleep analysis revealed that people who tend to stay more in bed sleep more.

6.	Future Works

ïƒ˜	Collect data which is more recent and include wide range of participants over a long duration of time.
ïƒ˜	Make the data available from the original source rather than first party data.
ïƒ˜	Introduce a reward-based system for participants so that the data is collected more precisely and consistently.
ïƒ˜	Make the watches with long lasting batteries and are more fashionable so that the customers would wear it most of the time.
ïƒ˜	Send timely reminders for walking, sleeping, and logging the data so that the participants feel motivated and achieve their activity, sleep goals.


